{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Corretor.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps51drInn7PZ"
      },
      "source": [
        "# Pré-corretor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylXFWrYQn4TV"
      },
      "source": [
        "with open('artigos.txt', 'r') as f:\n",
        "  artigos = f.read()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNJ4tHiwoPTH",
        "outputId": "b5971688-c236-448f-c996-1c89a54bac7a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EbJB0lxo1aG"
      },
      "source": [
        "## Tokenizando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trdHnj3VoPvA"
      },
      "source": [
        "def separa_palavras(lista_tokens):\n",
        "  lista_palavras  = []\n",
        "  for token in lista_tokens:\n",
        "    if token.isalpha() == True:\n",
        "      lista_palavras.append(token)\n",
        "  return lista_palavras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdXMnQDxoXqs"
      },
      "source": [
        "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
        "lista_palavras = separa_palavras(lista_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0lXmh3LossL",
        "outputId": "e86cac79-5ae1-4862-aac2-c2ef7fe8932a"
      },
      "source": [
        "print(f\"O número de palavras é {len(lista_palavras)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O número de palavras é 393914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rcpADdro3Mv"
      },
      "source": [
        "## Normalizando o texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmGGnhbgoxo1"
      },
      "source": [
        "def normalizacao(lista_palavras):\n",
        "  lista_normalizada = []\n",
        "  for palavra in lista_palavras:\n",
        "    lista_normalizada.append(palavra.lower())\n",
        "  return lista_normalizada\n",
        "lista_normalizada = normalizacao(lista_palavras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV-iaQIXveWp"
      },
      "source": [
        "vocabulario = set(lista_normalizada)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0GhVeA3pCZU"
      },
      "source": [
        "# Partes do corretor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaPu6MsnqpWy"
      },
      "source": [
        "def insere_letras(fatias):\n",
        "  novas_palavras = []\n",
        "  letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "  for E,D in fatias:\n",
        "    for letra in letras:\n",
        "      novas_palavras.append(E + letra + D)\n",
        "  return novas_palavras\n",
        "def deletando_caracteres(fatias):\n",
        "  novas_palavras = []\n",
        "  for E,D in fatias:\n",
        "    novas_palavras.append(E + D[1:])\n",
        "  return novas_palavras\n",
        "def troca_letra(fatias):\n",
        "  novas_palavras = []\n",
        "  letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "  for E,D in fatias:\n",
        "    for letra in letras:\n",
        "      novas_palavras.append(E + letra + D[1:])\n",
        "  return novas_palavras\n",
        "def inverte_letra(fatias):\n",
        "    novas_palavras = []\n",
        "    for E, D in fatias:\n",
        "        if len(D) > 1:\n",
        "          novas_palavras.append(E+D[1]+D[0]+D[2:])\n",
        "    return novas_palavras\n",
        "def gerador_palavras(palavra):\n",
        "  fatias =[]\n",
        "  for i in range(len(palavra)+1):\n",
        "    #temos que adicionar + 1 no range, pois senão não faria ('lgica','')\n",
        "    fatias.append((palavra[:i],palavra[i:]))\n",
        "  palavras_geradas = insere_letras(fatias)\n",
        "  palavras_geradas += deletando_caracteres(fatias)\n",
        "  palavras_geradas += troca_letra(fatias)\n",
        "  palavras_geradas += inverte_letra(fatias)\n",
        "  return palavras_geradas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ2-2lnlr4r6"
      },
      "source": [
        "## Corretor para dois erros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7AIuXlgr07I"
      },
      "source": [
        "def gerador_turbinado(palavras_geradas):\n",
        "    novas_palavras = []\n",
        "    for palavra in palavras_geradas:\n",
        "        novas_palavras += gerador_palavras(palavra)\n",
        "    return novas_palavras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrA6NxmZsVPU"
      },
      "source": [
        "# Corretor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7bYxNvTsZRO",
        "outputId": "2325cf6a-045f-4bb6-c864-53099ba8f50f"
      },
      "source": [
        "frequencia = nltk.FreqDist(lista_normalizada)\n",
        "total_palavras = len(lista_normalizada)\n",
        "frequencia.most_common(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 15494),\n",
              " ('o', 13966),\n",
              " ('que', 12225),\n",
              " ('a', 11034),\n",
              " ('e', 10478),\n",
              " ('para', 7694),\n",
              " ('um', 6346),\n",
              " ('é', 5881),\n",
              " ('uma', 5202),\n",
              " ('do', 5116)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBZ4WCSCvkyz"
      },
      "source": [
        "def probabilidade(palavras_geradas):\n",
        "  return frequencia[palavras_geradas]/total_palavras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ztw9XjOseog"
      },
      "source": [
        "def corretor(palavras):\n",
        "  palavras_geradas = gerador_palavras(palavras)\n",
        "  palavra_correta = max(palavras_geradas, key=probabilidade)\n",
        "  return palavra_correta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oudzvJ7csh0J"
      },
      "source": [
        "## Diminuindo o número de candidatos para a correção de dois erros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24MW6gIWshIZ"
      },
      "source": [
        "def novo_corretor(palavra):\n",
        "    palavras_geradas = gerador_palavras(palavra)\n",
        "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
        "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
        "    candidatos = [palavra]\n",
        "    for palavra in todas_palavras:\n",
        "        if palavra in vocabulario:\n",
        "          candidatos.append(palavra)\n",
        "    palavra_correta = max(candidatos, key=probabilidade)\n",
        "    return palavra_correta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPxHsHmkv-nM"
      },
      "source": [
        "# Avaliador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVUuGtnitFlm"
      },
      "source": [
        "def cria_dados_teste (nome_arquivo):\n",
        "  lista_palavras_teste = []\n",
        "  f = open(nome_arquivo, 'r')\n",
        "  for linha in f:\n",
        "    correta, errada = linha.split()\n",
        "    lista_palavras_teste.append((correta, errada))\n",
        "  f.close()\n",
        "  return lista_palavras_teste\n",
        "lista_teste = cria_dados_teste(\"palavras.txt\")\n",
        "lista_teste"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX5TO9GMw_k0"
      },
      "source": [
        "def avaliador (testes, vocabulario):\n",
        "  numero_palavras = len(testes)\n",
        "  acertou = 0\n",
        "  desconhecida = 0\n",
        "  for correta, errada in testes:\n",
        "    palavra_corrigida = novo_corretor(errada)\n",
        "    desconhecida += (correta not in vocabulario)\n",
        "    if palavra_corrigida == correta:\n",
        "      acertou += 1\n",
        "    else:\n",
        "       print(errada + \"-\" + corretor(errada) + \"-\" + palavra_corrigida)\n",
        "  taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
        "  taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
        "  print(f\"{taxa_acerto}% de {numero_palavras} palavras\")\n",
        "  print(f\"{taxa_desconhecida}% de {numero_palavras} palavras\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EPK09TtxF1B",
        "outputId": "eb40444b-cb73-4598-eccb-181c69803c2d"
      },
      "source": [
        "avaliador(lista_teste, vocabulario)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "esje-esse-se\n",
            "sãêo-são-não\n",
            "dosa-dos-do\n",
            "eme-em-de\n",
            "eàssa-essa-esse\n",
            "daõs-das-da\n",
            "céda-cada-da\n",
            "noâ-no-o\n",
            "enêão-então-não\n",
            "tĩem-tem-em\n",
            "nossah-nossa-nosso\n",
            "teb-tem-de\n",
            "atĩ-até-a\n",
            "âem-em-de\n",
            "foo-foi-o\n",
            "serr-ser-se\n",
            "entke-entre-então\n",
            "van-vai-a\n",
            "çeus-seus-seu\n",
            "eû-e-de\n",
            "temeo-tempo-temos\n",
            "semre-sempre-ser\n",
            "elaá-ela-ele\n",
            "síó-só-se\n",
            "siàe-site-se\n",
            "seém-sem-em\n",
            "peln-pelo-ele\n",
            "aléra-alura-agora\n",
            "tdia-dia-da\n",
            "jé-é-de\n",
            "sãô-são-não\n",
            "odos-dos-do\n",
            "siua-sua-seu\n",
            "elpe-ele-esse\n",
            "teos-temos-os\n",
            "eũsa-essa-esse\n",
            "vjmos-vamos-temos\n",
            "dms-dos-de\n",
            "cava-java-para\n",
            "ános-nos-no\n",
            "èaso-caso-as\n",
            "túem-tem-em\n",
            "daáos-dados-dos\n",
            "nossk-nosso-nosso\n",
            "tãer-ter-ser\n",
            "vté-até-é\n",
            "búm-bem-um\n",
            "sçerá-será-ser\n",
            "entró-entre-então\n",
            "uai-vai-a\n",
            "sâus-seus-seu\n",
            "ìeu-seu-de\n",
            "fual-qual-sua\n",
            "elal-ela-ele\n",
            "skó-só-se\n",
            "secm-sem-em\n",
            "aluéa-alura-além\n",
            "dil-dia-de\n",
            "sód-só-se\n",
            "eúaa-aeúaa-essa\n",
            "ró-só-de\n",
            "dĩaz-adĩaz-da\n",
            "correptor-corretor-correto\n",
            "trtica-tática-prática\n",
            "ewpoderamento-aewpoderamento-ewpoderamento\n",
            "îgato-gato-fato\n",
            "cakvalo-acakvalo-carvalho\n",
            "canelac-acanelac-janela\n",
            "tênisy-atênisy-tênisy\n",
            "anciosa-aanciosa-ansioso\n",
            "ancciosa-aancciosa-ancciosa\n",
            "ansioa-aansioa-ensina\n",
            "asterístico-aasterístico-asterístico\n",
            "entertido-aentertido-entendido\n",
            "ritimo-ritmo-ótimo\n",
            "indiota-aindiota-indica\n",
            "tomare-tomar-tomar\n",
            "seje-seja-se\n",
            "provalecer-aprovalecer-prevaleceu\n",
            "esteje-esteja-este\n",
            "mindigo-amindigo-indico\n",
            "pertubar-apertubar-derrubar\n",
            "55.91% de 186 palavras\n",
            "6.99% de 186 palavras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH_tfuyixSOl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT1gKvT3xb15"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zShL6AHvxcD5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}